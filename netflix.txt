ユーザの評価は以下の4要素によって行われる．
ここではユーザAが映画Eを評価したとする．
1. ベースライン(Eに対する全ユーザの平均評価)
2. ユーザAの評価傾向(Aは平均的なユーザよりも低い評価をつけがち)
3. 映画Eの評価傾向(Eは超いい映画だから予測値よりも高い評価を得る)
4. AとE間の特定の相互作用(AはEにでてる俳優とかEの設定(サスペンス，恋愛もの)が好き)

レコメンドを行うために上3つによる影響を除き，一番下のだけを予測対象とする．
予測の特徴量としては，以下のようなものがある．
・square root of the 最初に評価をつけた時からの日数->映画を見るにつれて評価が厳しくなるみたいなこと->日数より見た本数の方がいいのでは
・誰かが最初に映画Eに評価をつけた時からの日数->日数が短いほど，より熱狂的なファンとみなせる
・映画Eをレイティングした人の数
・映画の総合評価<-???
・(Plus a bunch of others)

bellkorもこういう地味なモデリング作業が予測精度のファクターになると言ってる

Neighborhood models
item-item approach:類似アイテムの集合を探す
user-user approach:類似ユーザを探す

ここでitem-item approachを例にとると
・どのように類似アイテムを探すのか
・平均をとるときに重みをかければ良いのか
という疑問が残る
→標準的な方法では類似度(相関，ジャカード係数など)行列を各ペアごとに求め，類似度上位K個を採用する．また，重みつけもこの類似度行列を用いて行う．

しかし，Neighborhood modelには幾つか問題がある
・neighborhoodは互いに独立でないため，重み付き平均に普通の類似度行列を用いると，それらの情報を過大評価することにつながってしまう．
ex) ロードオブザリング3部作は全てハリポタのneighborhoodだが，本質的な情報のみを抜き出す場合は3部作を1つ作品として扱うべき
・映画によってneighborhoodの数が違う．一つから強く推薦されるものや，いくつか推薦元を必要とするもの，全くneighborhoodを持たないものなど様々
→これまでのアルゴリズムを棄て去り，新たなモデルを構築する必要がある

・アイテム間の類似度として相関とかcosineを使うアプローチは使える
・ただし，平均計算の際の重みを求めるために「線形回帰」を使う必要がある．これは二乗誤差を最小化するものである．
(より複雑なuser-userアプローチも有効)

暗黙のデータ
オフセットのこと->ある映画のneighborに対する差

行列分解
上で示したneighborhoodモデルはとてもローカル(範囲が狭い)アプローチである一方，factorizationモデルはグローバルなアプローチである．
行列分解ではユーザ，movie行列を潜在的なファクターに分解する

BellKer saids
行列分解はとても柔軟性の高いモデルである一方，neighborhoodモデルもpopularである．それは新しい映画，ユーザの追加に再学習を必要としないためである．

最も典型的な行列分解手法はSVD(NMF)である．しかし，ここで行列の成分が0であることは超悪い評価ではなく，見てないことを意味することに注意が必要である．
NetFlix prizeで用いられている方法は以下の通り
standard SVD：行列をユーザーのファクター行列とmovieのファクター行列の分解
Asymmetric SVD：ユーザをアイテムの集合(ユーザが評価した映画の集合)で表現し，この集合のファクターベクトルとmovieのファクターベクトルの積で予測値を表現．
				standardに比べて，retrainingを必要としないという利点がある
SVD++：standard+asymmetricだよ

回帰
use-centric approach:PCA．MDS，SVDとか使える
movie-centric appriach:上と同じことをmovie軸からやる

RMB
多くのモデルはtemporal effect(時間に依存する評価の変化->だんだんコメディが好きになるとか)に弱い．matrix factrizatinoは時間依存に
強いけどもっと最近の行動に重みをおいたモデルが欲しいよね

過学習を防ぐための正則化は必要不可欠だよね

アンサンブル方法
gradient boosted dicision treeで500を超えるモデルをアンサンブル．
GBDTで有効なクラスタリングのpredictorは以下の通り
・ユーザが評価した映画の数
・映画を評価したユーザの数
・ユーザとmovieのファクターベクトル
・RBMの隠れ層

BellKor found
評価数が少ないときはRBMの方が有効で，評価数多いときはmfが有効
